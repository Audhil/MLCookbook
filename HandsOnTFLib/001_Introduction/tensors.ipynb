{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"code @ https://github.com/Audhil/tensorflow_cookbook/blob/master/01_Introduction/02_Creating_and_Using_Tensors/02_tensors.ipynb\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ops.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor:  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n   0.  0.]]\nmy_var:  [[ 0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.]]\nzero_var:  [[ 0.  0.  0.  0.]\n [ 0.  0.  0.  0.]]\nones_var:  [[ 1.  1.  1.  1.]\n [ 1.  1.  1.  1.]]\nzero_similar:  [[ 0.  0.  0.  0.]\n [ 0.  0.  0.  0.]]\nones_similar:  [[ 1.  1.  1.  1.]\n [ 1.  1.  1.  1.]]\nfill_var:  [[-4 -4 -4 -4]\n [-4 -4 -4 -4]]\nconst_var:  [8 6 7 5 3 0 9]\nconst_fill_var:  [[-3 -3 -3 -3]\n [-3 -3 -3 -3]]\nlin_var:  [ 3.  6.  9.]\nlin_var:  [3 6]\nrnorm_var:  [[ 0.63925219 -1.89646471  0.66266572 -1.2216959 ]\n [ 0.52498531  2.29509568 -0.44356921  0.77107173]]\nrunif_var:  [[ 1.94742846  3.35459542  5.67963028  5.56200027]\n [ 6.2623167   6.05349493  1.10954356  4.45236015]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val is x_place_holder :  [[ 0.0832231   0.64036244  0.47459567  0.11434632]\n [ 0.41869581  0.21303803  0.8208949   0.71896428]\n [ 0.99175733  0.53123635  0.82594967  0.65547204]\n [ 0.86242795  0.24927445  0.9708634   0.07480583]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \"\"\"Creating Tensors\"\"\"\n",
    "    my_tensor = tf.zeros([1, 20])\n",
    "    print('my_tensor: ', sess.run(my_tensor))\n",
    "    my_var = tf.Variable(tf.zeros([2, 5]))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('my_var: ', sess.run(my_var))\n",
    "    row_dim = 2\n",
    "    col_dim = 4\n",
    "    zero_var = tf.Variable(tf.zeros([row_dim, col_dim]))\n",
    "    ones_var = tf.Variable(tf.ones([row_dim, col_dim]))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('zero_var: ', sess.run(zero_var))\n",
    "    print('ones_var: ', sess.run(ones_var))\n",
    "    \"\"\"Creating Tensors Based on Other Tensor's Shape\"\"\"\n",
    "    zero_similar = tf.Variable(tf.zeros_like(zero_var))\n",
    "    ones_similar = tf.Variable(tf.ones_like(ones_var))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('zero_similar: ', sess.run(zero_similar))\n",
    "    print('ones_similar: ', sess.run(ones_similar))\n",
    "    \"\"\"Filling a Tensor with a Constant\"\"\"\n",
    "    fill_var = tf.Variable(tf.fill([row_dim, col_dim], -4))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('fill_var: ', sess.run(fill_var))\n",
    "    # Create a variable from a constant\n",
    "    const_var = tf.Variable(tf.constant([8, 6, 7, 5, 3, 0, 9]))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('const_var: ', sess.run(const_var))\n",
    "    const_fill_var = tf.Variable(tf.constant(-3, shape=[row_dim, col_dim]))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('const_fill_var: ', sess.run(const_fill_var))\n",
    "    \"\"\"Creating Tensors Based on Sequences and Ranges\"\"\"\n",
    "    # linspace - may be for float values\n",
    "    lin_var = tf.Variable(tf.linspace(start=3., stop=9., num=3))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('lin_var: ', sess.run(lin_var))\n",
    "    # range\n",
    "    rang_var = tf.Variable(tf.range(start=3, limit=9, delta=3))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('lin_var: ', sess.run(rang_var))\n",
    "    \"\"\"Random Number Tensors\"\"\"\n",
    "    rnorm_var = tf.random_normal([row_dim, col_dim], stddev=1.0, mean=0.0)\n",
    "    print('rnorm_var: ', sess.run(rnorm_var))\n",
    "    runif_var = tf.random_uniform([row_dim, col_dim], minval=1, maxval=7)\n",
    "    print('runif_var: ', sess.run(runif_var))\n",
    "\n",
    "    \"\"\"Visualizing the Variable Creation in TensorBoard\"\"\"\n",
    "    # Create variable\n",
    "    my_var = tf.Variable(tf.zeros([1, 20]))\n",
    "    # Add summaries to tensorboard\n",
    "    merged = tf.summary.merge_all()\n",
    "    # Initialize graph writer\n",
    "    writer = tf.summary.FileWriter(\"/tmp/var_logs\", graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \"\"\"\n",
    "    We now run the following command in our command prompt:\n",
    "    tensorboard --logdir=/tmp\n",
    "    And it will tell us the URL we can navigate our browser to to see Tensorboard. The default should be:\n",
    "    http://0.0.0.0:6006/\n",
    "    \"\"\"\n",
    "    \"\"\"Placeholder\"\"\"\n",
    "    x_place_holder = tf.placeholder(tf.float32, shape=(4, 4))\n",
    "    print('val is x_place_holder : ', sess.run(x_place_holder, feed_dict={x_place_holder: np.random.rand(4, 4)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n [ 0.  1.  0.]\n [ 0.  0.  1.]]\n[[-1.14567637  0.48116842 -0.38919345]\n [ 1.52407587  0.38032597 -0.38250005]]\n[[ 44.  44.  44.]\n [ 44.  44.  44.]]\nC :  [[ 0.44361913  0.60667312  0.42279303]\n [ 0.24857605  0.76454198  0.65443778]]\n[[ 1.  2.  3.]\n [-3. -7. -1.]\n [ 0.  5. -2.]]\n[[ 44.35493469  43.10300064  45.83303452]\n [ 43.26262665  44.31661987  43.14339066]]\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\n[[ 44.  44.  44.]\n [ 44.  44.  44.]]\nD transpose :  [[ 1. -3.  0.]\n [ 2. -7.  5.]\n [ 3. -1. -2.]]\nmatrix_determinant :  -38.0\n[[ 1.  0.  0.]\n [ 0.  1.  0.]\n [ 0.  0.  1.]]\neigenvalues :  [-10.65907521  -0.22750691   2.88658212]\neigenvectors :  [[ 0.21749542  0.63250104 -0.74339638]\n [ 0.84526515  0.2587998   0.46749277]\n [-0.4880805   0.73004459  0.47834331]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Matrices and Matrix Operations\"\"\"\n",
    "\"\"\"Declaring matrices\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    # identity matrix\n",
    "    identity_matrix = tf.diag([1., 1., 1.])\n",
    "    print(sess.run(identity_matrix))\n",
    "    # 2x3 random norm matrix\n",
    "    A = tf.truncated_normal([2, 3])\n",
    "    print(sess.run(A))\n",
    "    # 2x3 constant matrix\n",
    "    B = tf.fill([2, 3], 44.)\n",
    "    print(sess.run(B))\n",
    "    # 3x2 random uniform matrix\n",
    "    C = tf.random_uniform([2, 3])\n",
    "    print('C : ', sess.run(C))\n",
    "    # Create matrix from np array\n",
    "    D = tf.convert_to_tensor(np.array([[1., 2., 3.], [-3., -7., -1.], [0., 5., -2.]]))\n",
    "    print(sess.run(D))\n",
    "    \"\"\"Matrix Operations\"\"\"\n",
    "    print(sess.run(A + B))\n",
    "    print(sess.run(B - B))\n",
    "    print(sess.run(tf.matmul(B, identity_matrix)))\n",
    "    print('D transpose : ', sess.run(tf.transpose(D)))\n",
    "    print('matrix_determinant : ', sess.run(tf.matrix_determinant(D)))\n",
    "    \"\"\"Cholesky Decomposition\"\"\"\n",
    "    print(sess.run(tf.cholesky(identity_matrix)))\n",
    "    eigenvalues, eigenvectors = sess.run(tf.self_adjoint_eig(D))\n",
    "    print('eigenvalues : ', eigenvalues)\n",
    "    print('eigenvectors : ', eigenvectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n0.75\n0.0\n2.0\n[ 0.  0.  1.]\n-7.23998e-06\n-1.0\n1.0\n362\nexpected_output :  [10, 12, 20, 34, 54, 80, 112, 150, 194, 244, 300, 362, 430, 504, 584]\ncustom_polynomial output :  10\ncustom_polynomial output :  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_polynomial output :  20\ncustom_polynomial output :  34\ncustom_polynomial output :  54\ncustom_polynomial output :  80\ncustom_polynomial output :  112\ncustom_polynomial output :  150\ncustom_polynomial output :  194\ncustom_polynomial output :  244\ncustom_polynomial output :  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_polynomial output :  362\ncustom_polynomial output :  430\ncustom_polynomial output :  504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_polynomial output :  584\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Operations\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    # divisions\n",
    "    print(sess.run(tf.div(3, 6)))\n",
    "    print(sess.run(tf.truediv(3, 4)))\n",
    "    print(sess.run(tf.floordiv(3.0, 4.0)))\n",
    "    # mods\n",
    "    print(sess.run(tf.mod(22.0, 5.0)))\n",
    "    # cross products\n",
    "    print(sess.run(tf.cross([1., 0., 0.], [0., 1., 0.])))\n",
    "\n",
    "    # trig functions\n",
    "    print(sess.run(tf.sin(3.1416)))\n",
    "    print(sess.run(tf.cos(3.1416)))\n",
    "    print(sess.run(tf.div(tf.sin(3.1416 / 4.), tf.cos(3.1416 / 4.))))\n",
    "\n",
    "    # Custom operations\n",
    "    test_nums = range(15)\n",
    "\n",
    "    def custom_polynomial(x_val):\n",
    "        # Return 3x^2 - x + 10\n",
    "        return tf.subtract(3 * tf.square(x_val), x_val) + 10\n",
    "\n",
    "    print(sess.run(custom_polynomial(11)))\n",
    "    expected_output = [3 * x * x - x + 10 for x in test_nums]\n",
    "    print('expected_output : ', expected_output)\n",
    "    [print('custom_polynomial output : ', sess.run(custom_polynomial(num))) for num in test_nums]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Activation functions\"\"\"\n",
    "\"\"\"1. refer images in the folder\"\"\"\n",
    "\"\"\"2. refer activation_functions.txt for more info\"\"\"\n",
    "# x_vals = tf.linspace(start=-10., stop=10., num=1000)\n",
    "x_vals = tf.linspace(start=-10., stop=10., num=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\nrelu(x_vals) :  [  0.   0.   0.   5.  10.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ReLU activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_relu = sess.run(tf.nn.relu(x_vals))\n",
    "    print('relu(x_vals) : ', y_relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu6(x_vals) :  [ 0.  0.  0.  5.  6.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ReLU-6 activation\"\"\"\n",
    "# x_vals = tf.convert_to_tensor([-2, 3, 55, 7, -1, 0])\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_relu6 = sess.run(tf.nn.relu6(x_vals))\n",
    "    print('relu6(x_vals) : ', y_relu6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\nsigmoid(x_vals) :  [  4.53978719e-05   6.69285096e-03   5.00000000e-01   9.93307173e-01\n   9.99954581e-01]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sigmoid activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_sigmoid = sess.run(tf.nn.sigmoid(x_vals))\n",
    "    print('sigmoid(x_vals) : ', y_sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\ntanh(x_vals) :  [-1.         -0.99990916  0.          0.99990916  1.        ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"tanh activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_tanh = sess.run(tf.nn.tanh(x_vals))\n",
    "    print('tanh(x_vals) : ', y_tanh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\nsoftsign(x_vals) :  [-0.90909094 -0.83333331  0.          0.83333331  0.90909094]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Softsign activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_softsign = sess.run(tf.nn.softsign(x_vals))\n",
    "    print('softsign(x_vals) : ', y_softsign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\nsoftplus(x_vals) :  [  4.54177061e-05   6.71534892e-03   6.93147182e-01   5.00671530e+00\n   1.00000458e+01]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Softplus activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_softplus = sess.run(tf.nn.softplus(x_vals))\n",
    "    print('softplus(x_vals) : ', y_softplus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vals :  [-10.  -5.   0.   5.  10.]\nelu(x_vals) :  [ -0.99995458  -0.99326205   0.           5.          10.        ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Exponential Linear activation\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    print('x_vals : ', sess.run(x_vals))\n",
    "    y_elu = sess.run(tf.nn.elu(x_vals))\n",
    "    print('elu(x_vals) : ', y_elu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'ndim'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-419-f4f0d4b71a5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_softplus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Softplus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ReLU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_relu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ReLU6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_elu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ExpLU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m    244\u001b[0m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[1;32m    247\u001b[0m                              \"shapes {} and {}\".format(x.shape, y.shape))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ndim'"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nauJ/Acz2XLpusNoKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11333f278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_vals, y_softplus, 'r--', label='Softplus', linewidth=2)\n",
    "plt.plot(x_vals, y_relu, 'b:', label='ReLU', linewidth=2)\n",
    "plt.plot(x_vals, y_relu6, 'g-.', label='ReLU6', linewidth=2)\n",
    "plt.plot(x_vals, y_elu, 'k-', label='ExpLU', linewidth=0.5)\n",
    "plt.ylim([-1.5, 7])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x_vals, y_sigmoid, 'r--', label='Sigmoid', linewidth=2)\n",
    "plt.plot(x_vals, y_tanh, 'b:', label='Tanh', linewidth=2)\n",
    "plt.plot(x_vals, y_softsign, 'g-.', label='Softsign', linewidth=2)\n",
    "plt.ylim([-2, 2])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"something idiotic kinda error, leaving it as of now!\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"relu.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

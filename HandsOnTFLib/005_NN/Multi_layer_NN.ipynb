{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Multi Layer NN\n",
    "src code @ https://github.com/Audhil/tensorflow_cookbook/blob/master/06_Neural_Networks/06_Using_Multiple_Layers/06_using_a_multiple_layer_network.ipynb\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low Birth Rate Data\n",
    "# Columns    Variable                                      Abbreviation\n",
    "# ---------------------------------------------------------------------\n",
    "# Low Birth Weight (0 = Birth Weight >= 2500g,            LOW\n",
    "#                          1 = Birth Weight < 2500g)\n",
    "# Age of the Mother in Years                              AGE\n",
    "# Weight in Pounds at the Last Menstrual Period           LWT\n",
    "# Race (1 = White, 2 = Black, 3 = Other)                  RACE\n",
    "# Smoking Status During Pregnancy (1 = Yes, 0 = No)       SMOKE\n",
    "# History of Premature Labor (0 = None  1 = One, etc.)    PTL\n",
    "# History of Hypertension (1 = Yes, 0 = No)               HT\n",
    "# Presence of Uterine Irritability (1 = Yes, 0 = No)      UI\n",
    "# Birth Weight in Grams                                   BWT\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "birth_weight_file = 'birth_weight.csv'\n",
    "\n",
    "# making a file if not exists\n",
    "if not os.path.exists(birth_weight_file):\n",
    "    birth_url = 'https://github.com/nfmcclure/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n",
    "    birth_file = requests.get(birth_url)\n",
    "    birth_data = birth_file.text.split('\\r\\n')\n",
    "    birth_header = birth_data[0].split('\\t')\n",
    "    birth_data = [[float(x) for x in y.split('\\t') if len(x) >= 1] for y in birth_data[1:] if len(y) >= 1]\n",
    "    with open(birth_weight_file, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([birth_header])\n",
    "        writer.writerows(birth_data)\n",
    "        f.close()\n",
    "\n",
    "# read the file to memory\n",
    "birth_data = []\n",
    "with open(birth_weight_file, newline='') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    birth_header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        birth_data.append(row)\n",
    "\n",
    "# making everything to flow\n",
    "birth_data = [[float(x) for x in row] for row in birth_data]\n",
    "\n",
    "# y_targets\n",
    "y_vals = np.array([x[8] for x in birth_data])\n",
    "\n",
    "# Filter for features of interest\n",
    "cols_of_interest = ['AGE', 'LWT', 'RACE', 'SMOKE', 'PTL', 'HT', 'UI']\n",
    "x_vals = np.array(\n",
    "    [[x[ix] for ix, feature in enumerate(birth_header) if feature in cols_of_interest] for x in birth_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_index:\n [139  35  49  72  34  11  89 132  85   0  94  97 149  29   7  76  57 108\n  21  94  41  34 143  22  45  36  90  52   9 147  69 140  26  43 119  18\n  64  78 122  26   3  21 110 122  76  18  34  92   6 147  60 118 109  39\n  64  60 140 121   4  42 125  58 149   0  35  77  21  68  93  69 125 113\n  45  65  25 115  26 150  76  11  30  79 131  70  46  47 142  75   5 119\n  38  50  18  29  21 140  23  17  36   7]\nrand_x\n [[ 0.0952381   0.32352941  0.          1.          0.          0.          0.        ]\n [ 0.0952381   0.32352941  0.          1.          0.          0.          0.        ]\n [ 0.52380952  0.14705882  1.          0.          1.          0.          0.        ]\n [ 0.23809524  0.18823529  0.          1.          0.          0.          1.        ]\n [ 0.38095238  0.29411765  0.          1.          0.          0.          0.        ]\n [ 0.28571429  0.52941176  0.          1.          0.          0.          0.        ]\n [ 0.57142857  0.19411765  0.          1.          0.          0.          0.        ]\n [ 0.33333333  0.61764706  1.          1.          0.          0.          0.        ]\n [ 0.33333333  0.64705882  1.          0.          0.          0.          1.        ]\n [ 0.80952381  0.12941176  0.          1.          1.          0.          0.        ]\n [ 0.23809524  0.06470588  0.          1.          1.          0.          1.        ]\n [ 0.76190476  0.18823529  0.          0.          0.          0.          0.        ]\n [ 0.52380952  0.05294118  1.          0.          1.          0.          0.        ]\n [ 0.71428571  0.29411765  0.          1.          0.          0.          0.        ]\n [ 0.28571429  0.14705882  1.          0.          0.          0.          0.        ]\n [ 0.19047619  0.15882353  0.          1.          0.          0.          1.        ]\n [ 0.52380952  0.20588235  1.          0.          0.          0.          0.        ]\n [ 0.42857143  0.25294118  1.          0.          0.          0.          0.        ]\n [ 0.76190476  0.33529412  0.          0.          0.          0.          0.        ]\n [ 0.23809524  0.06470588  0.          1.          1.          0.          1.        ]\n [ 0.85714286  0.52941176  0.          0.          0.          0.          0.        ]\n [ 0.38095238  0.29411765  0.          1.          0.          0.          0.        ]\n [ 0.66666667  0.08823529  0.          1.          0.          0.          0.        ]\n [ 0.          0.32352941  0.          0.          1.          0.          0.        ]\n [ 0.38095238  0.02941176  1.          1.          0.          0.          0.        ]\n [ 0.23809524  0.91176471  0.          1.          0.          1.          0.        ]\n [ 0.52380952  0.22352941  0.          1.          0.          0.          0.        ]\n [ 0.52380952  0.23529412  1.          0.          0.          0.          1.        ]\n [ 0.28571429  0.23529412  1.          0.          0.          0.          1.        ]\n [ 0.14285714  0.23529412  1.          0.          0.          0.          0.        ]\n [ 0.04761905  0.20588235  1.          0.          0.          0.          1.        ]\n [ 0.76190476  0.42941176  1.          0.          0.          0.          0.        ]\n [ 0.66666667  0.23529412  0.          1.          0.          0.          0.        ]\n [ 0.66666667  1.          1.          1.          0.          0.          0.        ]\n [ 0.28571429  0.45882353  0.          0.          0.          0.          0.        ]\n [ 0.38095238  0.28823529  0.          0.          0.          0.          0.        ]\n [ 0.          0.12352941  1.          1.          1.          0.          0.        ]\n [ 0.28571429  0.24117647  1.          1.          0.          0.          0.        ]\n [ 0.28571429  0.14705882  0.          1.          0.          0.          0.        ]\n [ 0.66666667  0.23529412  0.          1.          0.          0.          0.        ]\n [ 0.23809524  0.41176471  1.          0.          0.          0.          0.        ]\n [ 0.76190476  0.33529412  0.          0.          0.          0.          0.        ]\n [ 0.23809524  0.6         1.          0.          0.          0.          1.        ]\n [ 0.28571429  0.14705882  0.          1.          0.          0.          0.        ]\n [ 0.19047619  0.15882353  0.          1.          0.          0.          1.        ]\n [ 0.38095238  0.28823529  0.          0.          0.          0.          0.        ]\n [ 0.38095238  0.29411765  0.          1.          0.          0.          0.        ]\n [ 0.85714286  0.14705882  1.          1.          0.          0.          0.        ]\n [ 0.42857143  0.1         1.          0.          0.          0.          1.        ]\n [ 0.14285714  0.23529412  1.          0.          0.          0.          0.        ]\n [ 0.19047619  0.11764706  0.          1.          0.          0.          0.        ]\n [ 0.0952381   0.17647059  1.          0.          0.          0.          0.        ]\n [ 0.19047619  0.11764706  1.          1.          0.          0.          0.        ]\n [ 0.71428571  0.25294118  0.          1.          0.          0.          0.        ]\n [ 0.          0.12352941  1.          1.          1.          0.          0.        ]\n [ 0.19047619  0.11764706  0.          1.          0.          0.          0.        ]\n [ 0.76190476  0.42941176  1.          0.          0.          0.          0.        ]\n [ 0.38095238  0.3         0.          0.          0.          0.          0.        ]\n [ 0.42857143  0.62941176  1.          1.          0.          0.          0.        ]\n [ 0.38095238  0.08823529  1.          0.          0.          1.          0.        ]\n [ 0.0952381   0.52941176  1.          0.          0.          0.          0.        ]\n [ 0.52380952  0.07058824  0.          1.          0.          0.          0.        ]\n [ 0.52380952  0.05294118  1.          0.          1.          0.          0.        ]\n [ 0.80952381  0.12941176  0.          1.          1.          0.          0.        ]\n [ 0.0952381   0.32352941  0.          1.          0.          0.          0.        ]\n [ 0.80952381  0.41176471  1.          1.          0.          0.          0.        ]\n [ 0.76190476  0.33529412  0.          0.          0.          0.          0.        ]\n [ 0.42857143  0.29411765  1.          0.          0.          0.          0.        ]\n [ 0.66666667  0.51176471  0.          0.          0.          0.          0.        ]\n [ 0.04761905  0.20588235  1.          0.          0.          0.          1.        ]\n [ 0.0952381   0.52941176  1.          0.          0.          0.          0.        ]\n [ 0.47619048  0.17647059  0.          0.          1.          0.          0.        ]\n [ 0.38095238  0.02941176  1.          1.          0.          0.          0.        ]\n [ 0.38095238  0.29411765  0.          1.          1.          0.          1.        ]\n [ 0.85714286  0.30588235  0.          0.          0.          0.          0.        ]\n [ 0.33333333  0.11764706  1.          0.          1.          0.          0.        ]\n [ 0.66666667  0.23529412  0.          1.          0.          0.          0.        ]\n [ 0.57142857  0.09411765  1.          0.          0.          0.          0.        ]\n [ 0.19047619  0.15882353  0.          1.          0.          0.          1.        ]\n [ 0.28571429  0.52941176  0.          1.          0.          0.          0.        ]\n [ 0.33333333  0.20588235  0.          0.          0.          0.          0.        ]\n [ 0.42857143  0.22941176  1.          0.          0.          0.          0.        ]\n [ 0.80952381  0.11764706  0.          0.          0.          0.          1.        ]\n [ 0.14285714  0.36470588  1.          0.          0.          1.          0.        ]\n [ 0.47619048  0.44117647  0.          1.          1.          0.          0.        ]\n [ 0.47619048  0.14705882  1.          1.          0.          0.          0.        ]\n [ 1.          0.52941176  0.          0.          1.          0.          0.        ]\n [ 0.52380952  0.35294118  0.          0.          0.          0.          0.        ]\n [ 0.52380952  0.44117647  0.          1.          1.          0.          0.        ]\n [ 0.28571429  0.45882353  0.          0.          0.          0.          0.        ]\n [ 0.33333333  0.25882353  1.          0.          0.          0.          0.        ]\n [ 0.66666667  0.35294118  0.          0.          0.          0.          0.        ]\n [ 0.38095238  0.28823529  0.          0.          0.          0.          0.        ]\n [ 0.71428571  0.29411765  0.          1.          0.          0.          0.        ]\n [ 0.76190476  0.33529412  0.          0.          0.          0.          0.        ]\n [ 0.76190476  0.42941176  1.          0.          0.          0.          0.        ]\n [ 0.28571429  0.41176471  0.          1.          0.          0.          0.        ]\n [ 0.14285714  0.22941176  1.          0.          0.          0.          0.        ]\n [ 0.23809524  0.91176471  0.          1.          0.          1.          0.        ]\n [ 0.28571429  0.14705882  1.          0.          0.          0.          0.        ]]\nrand_y\n [[ 3643.]\n [ 3374.]\n [ 2240.]\n [ 2084.]\n [ 2410.]\n [ 3940.]\n [ 2665.]\n [ 3042.]\n [ 1928.]\n [ 2353.]\n [ 1885.]\n [ 3799.]\n [ 2055.]\n [ 3884.]\n [ 2450.]\n [ 2600.]\n [ 1893.]\n [ 3544.]\n [ 3699.]\n [ 1885.]\n [ 3473.]\n [ 2410.]\n [ 2466.]\n [ 3941.]\n [ 3090.]\n [ 3629.]\n [ 2782.]\n [ 2877.]\n [ 2807.]\n [ 2438.]\n [ 2381.]\n [ 3203.]\n [ 2821.]\n [ 3303.]\n [ 3997.]\n [ 4111.]\n [ 2466.]\n [ 3444.]\n [ 2557.]\n [ 2821.]\n [ 2733.]\n [ 3699.]\n [ 2523.]\n [ 2557.]\n [ 2600.]\n [ 4111.]\n [ 2410.]\n [ 1818.]\n [ 1588.]\n [ 2438.]\n [ 2769.]\n [ 3175.]\n [ 2769.]\n [ 2663.]\n [ 2466.]\n [ 2769.]\n [ 3203.]\n [ 3460.]\n [ 2367.]\n [ 2750.]\n [ 3860.]\n [ 1928.]\n [ 2055.]\n [ 2353.]\n [ 3374.]\n [ 3321.]\n [ 3699.]\n [ 3062.]\n [ 2877.]\n [ 2381.]\n [ 3860.]\n [ 3770.]\n [ 3090.]\n [ 2187.]\n [ 3080.]\n [ 2301.]\n [ 2821.]\n [ 2325.]\n [ 2600.]\n [ 3940.]\n [ 4054.]\n [ 3232.]\n [ 2835.]\n [ 2495.]\n [ 1936.]\n [ 2381.]\n [ 4174.]\n [ 3416.]\n [ 2977.]\n [ 3997.]\n [ 2622.]\n [ 3234.]\n [ 4111.]\n [ 3884.]\n [ 3699.]\n [ 3203.]\n [ 1928.]\n [ 3225.]\n [ 3629.]\n [ 2450.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 25. Loss = 2941.31\nGeneration: 50. Loss = 2949.85\nGeneration: 75. Loss = 2963.04\nGeneration: 100. Loss = 2890.76\nGeneration: 125. Loss = 2818.66\nGeneration: 150. Loss = 2895.48\nGeneration: 175. Loss = 2820.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 200. Loss = 2860.97\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f5b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "# tuning knobs\n",
    "batch_size = 100\n",
    "learning_rate = .05\n",
    "\n",
    "# make results reproducible\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals) * 0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "\n",
    "# Normalize by column (min-max norm to be between 0 and 1)\n",
    "def normalize_cols(m):\n",
    "    col_max = m.max(axis=0)\n",
    "    col_min = m.min(axis=0)\n",
    "    return (m - col_min) / (col_max - col_min)\n",
    "\n",
    "\n",
    "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
    "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n",
    "\n",
    "\n",
    "# Define Variable Functions (weights and bias)\n",
    "def init_weight(shape, st_dev):\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return weight\n",
    "\n",
    "\n",
    "def init_bias(shape, st_dev):\n",
    "    bias = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return bias\n",
    "\n",
    "\n",
    "# Create Placeholders\n",
    "x_data = tf.placeholder(shape=[None, 7], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Create a fully connected layer:\n",
    "def fully_connected(input_layer, weights, biases):\n",
    "    layer = tf.add(tf.matmul(input_layer, weights), biases)\n",
    "    return tf.nn.relu(layer)\n",
    "\n",
    "\n",
    "# --------Create the first layer (50 hidden nodes)--------\n",
    "weight_1 = init_weight(shape=[7, 25], st_dev=10.0)\n",
    "bias_1 = init_bias(shape=[25], st_dev=10.0)\n",
    "layer_1 = fully_connected(x_data, weight_1, bias_1)\n",
    "\n",
    "# --------Create the second layer (25 hidden nodes)--------\n",
    "weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n",
    "bias_2 = init_bias(shape=[10], st_dev=10.0)\n",
    "layer_2 = fully_connected(layer_1, weight_2, bias_2)\n",
    "\n",
    "# --------Create third layer (5 hidden nodes)--------\n",
    "weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n",
    "bias_3 = init_bias(shape=[3], st_dev=10.0)\n",
    "layer_3 = fully_connected(layer_2, weight_3, bias_3)\n",
    "\n",
    "# --------Create output layer (1 output value)--------\n",
    "weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n",
    "bias_4 = init_bias(shape=[1], st_dev=10.0)\n",
    "final_output = fully_connected(layer_3, weight_4, bias_4)\n",
    "\n",
    "# L1 loss function\n",
    "loss = tf.reduce_mean(tf.abs(final_output - y_target))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "init_vars = tf.global_variables_initializer()\n",
    "\n",
    "rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "print('rand_index:\\n', rand_index)\n",
    "rand_x = x_vals_train[rand_index]\n",
    "rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "# rand_y = y_vals_train[rand_index]\n",
    "print('rand_x\\n', rand_x)\n",
    "print('rand_y\\n', rand_y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_vars)\n",
    "    loss_vec = []\n",
    "    test_loss = []\n",
    "    for i in range(200):\n",
    "        rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "        rand_x = x_vals_train[rand_index]\n",
    "        rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "        sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        loss_vec.append(temp_loss)\n",
    "        test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
    "        test_loss.append(test_temp_loss)\n",
    "        if (i + 1) % 25 == 0:\n",
    "            print('Generation: ' + str(i + 1) + '. Loss = ' + str(temp_loss))\n",
    "\n",
    "    % matplotlib inline\n",
    "    # Plot loss (MSE) over time\n",
    "    plt.plot(loss_vec, 'k-', label='Train Loss')\n",
    "    plt.plot(test_loss, 'r--', label='Test Loss')\n",
    "    plt.title('Loss (MSE) per Generation')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 40000)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

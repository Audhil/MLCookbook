{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "import os\n",
    "\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "We create a regression example as follows. The input data will be 100 random samples from a normal (mean of 1.0, stdev of 0.1). \n",
    "The target will be 100 constant values of 10.0.\n",
    "\n",
    "We will fit the regression model:  x_data * A = target_values\n",
    "Theoretically, we know that A should be equal to 10.0.\n",
    "\n",
    "\"\"\"src code: https://github.com/Audhil/tensorflow_cookbook/blob/master/02_TensorFlow_Way/05_Implementing_Back_Propagation/05_back_propagation.ipynb\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .02\n",
    "display_step = 25\n",
    "graph_dir = 'regression_graph_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is 0 while starting\nstep 25  value of A : [ 6.47467422]\ncost/loss : 15.031449\nstep 50  value of A : [ 8.67575169]\ncost/loss : 3.185009\nstep 75  value of A : [ 9.44034958]\ncost/loss : 3.291631\nstep 100  value of A : [ 9.96576405]\ncost/loss : 0.123963\n"
     ]
    }
   ],
   "source": [
    "# random values for demoing\n",
    "# for more info https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.normal.html\n",
    "x_vals = np.random.normal(1, .1, 100)  # gaussian distribution\n",
    "y_target_vals = np.repeat(10., 100)\n",
    "\n",
    "x_place_holder = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_place_holder = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "\n",
    "# Variable to find\n",
    "A = tf.Variable(tf.random_normal(shape=[1]))\n",
    "\n",
    "# regression => A * x\n",
    "y_pred = tf.multiply(x_place_holder, A)\n",
    "\n",
    "# loss function\n",
    "# we are using L2 loss function\n",
    "loss = tf.square(y_pred - y_place_holder)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "var_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)  # initialize variables\n",
    "    print('A is %d while starting' % (sess.run(A)))\n",
    "    for i in range(100):\n",
    "        random_selection = np.random.choice(100)\n",
    "        sess.run(optimizer, feed_dict={x_place_holder: [x_vals[random_selection]],\n",
    "                                       y_place_holder: [y_target_vals[random_selection]]})\n",
    "\n",
    "        if (i + 1) % display_step == 0:\n",
    "            print('step %d ' % (i + 1), 'value of A : ' + str(sess.run(A)))\n",
    "            print('cost/loss : %f' % (sess.run(loss, feed_dict={x_place_holder: [x_vals[random_selection]],\n",
    "                                                                y_place_holder: [y_target_vals[random_selection]]})))\n",
    "\n",
    "    # tensorboard graph\n",
    "    merged = tf.summary.merge_all(key='summary')\n",
    "\n",
    "    if not os.path.exists(graph_dir):\n",
    "        os.mkdir(graph_dir)\n",
    "\n",
    "    tf.summary.FileWriter(graph_dir, sess.graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
